{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Allow pretty printing of pandas dataframes etc\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report,\\\n",
    "precision_score, recall_score, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show more rows and columns by default\n",
    "pd.options.display.max_seq_items = 500\n",
    "pd.set_option('max_rows', 500)\n",
    "pd.set_option('max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('OnlineNewsPopularity/OnlineNewsPopularity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the actual number of shares is too difficult, so bin share counts into\n",
    "# '1' and '0' and use this as a classification target instead.\n",
    "# Note that it's important to use the specific labels 0 and 1 for binary outputs to\n",
    "# use sklearn's precision and recall metrics.\n",
    "news_df['share_bins'] = pd.qcut(news_df[' shares'],\n",
    "                                q=2,\n",
    "                                labels=[0, 1])\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-predictive column(s), target to make X_df\n",
    "X_df = news_df.drop(['url', ' shares', 'share_bins'], axis=1)\n",
    "display(X_df.head())\n",
    "\n",
    "# Put X into a numpy array for sklearn\n",
    "X = np.array(X_df)\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target to make y and put it into a numpy array for sklearn\n",
    "y = news_df['share_bins']\n",
    "y = np.array(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 10 elements of (X, y) side by side\n",
    "for a, b in zip(X[:10], y[:10]):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "y_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DT model on the training set\n",
    "dt_model = DecisionTreeClassifier(min_samples_leaf=20)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default model score for a decision tree is the accuracy\n",
    "print(dt_model.score(X_train, y_train))\n",
    "print(dt_model.score(X_test, y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RF model on the training set\n",
    "rf_model = RandomForestClassifier(max_features='auto', min_samples_leaf=20, n_estimators=10)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default model score for a random forest is the accuracy\n",
    "print(rf_model.score(X_train, y_train))\n",
    "print(rf_model.score(X_test, y_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_actual,\n",
    "                            y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'n_estimators': [10, 100, 500],\n",
    "    'min_samples_leaf': [1, 5, 10, 20, 40]\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'n_estimators': [500],\n",
    "    'min_samples_leaf': [20]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# By default GridSearchCV uses 3-fold cross-validation. Using more folds would be nice but\n",
    "# can be rather slow as we have to retrain the model for each fold.\n",
    "# Specifying refit=True refits the model using the best parameters over the whole dataset,\n",
    "# allowing us to use grid_search_model directly for predictions after training\n",
    "grid_search_model = GridSearchCV(estimator=rf_model,\n",
    "                                 param_grid=param_grid,\n",
    "                                 refit=True)\n",
    "grid_search_model.fit(X_train, y_train)\n",
    "grid_search_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best RF estimator over the test set\n",
    "print(grid_search_model.score(X_train, y_train))\n",
    "print(grid_search_model.score(X_test, y_actual))\n",
    "\n",
    "y_pred = grid_search_model.predict(X_test)\n",
    "print(classification_report(y_actual,\n",
    "                            y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF gives us pretty good probability estimates, so let's look at precision vs recall\n",
    "# as we vary the probability threshold\n",
    "y_pred_probs = grid_search_model.predict_proba(X_test)\n",
    "print(\"Some example probabilities:\", y_pred_probs[:10])\n",
    "\n",
    "# y_pred_probs contains probabilities for both '1' and '0'. We only\n",
    "# care about the probabilities of '1', so we extract it below.\n",
    "high_index = grid_search_model.best_estimator_.classes_.tolist().index(1)\n",
    "y_high_probs = [y_pred_probs[i, high_index] for i in range(y_pred_probs.shape[0])]\n",
    "\n",
    "print(\"Just the '1' probabilities:\", y_high_probs[:10])\n",
    "\n",
    "average_precision = average_precision_score(y_actual, y_high_probs)\n",
    "precisions, recalls, _ = precision_recall_curve(y_actual,\n",
    "                                                y_high_probs)\n",
    "\n",
    "print(\"Average precision is\", average_precision)\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 feature importances\n",
    "# zip returns an iterator in Python 3 (so as not to waste memory by creating all elements\n",
    "# unnecessarily), hence the conversion into a list\n",
    "features_importances = list(zip(X_df.columns, grid_search_model.best_estimator_.feature_importances_))\n",
    "features_importances.sort(key=lambda x:x[1], reverse=True)\n",
    "features_importances[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
