{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Quiz\n",
    "\n",
    "0. What is classification? What is regression?\n",
    "\n",
    "1. What's the difference between classification and regression?\n",
    "\n",
    "*Suppose we have a data set with a number of inputs together with corresponding targets. In both classification and regression, what we want to do is learn from the data set the relationship between the inputs and the targets. In other words, given a new data point's input, we want to predict the target using the learned relationship.*\n",
    "\n",
    "*In classification, this target is *categorical*, e.g something like \"dog\", \"cat\", \"sheep\" if the target is an animal.*\n",
    "\n",
    "*In regression, the target is a *real number*, e.g. something like 25.1 for a temperature target or 180cm for a height target.*\n",
    "\n",
    "2. Why is dimensionality reduction useful?\n",
    "\n",
    "*High-dimensional data is hard to visualise and often hard to train a machine learning model on due to the *curse of dimensionality*.*\n",
    "\n",
    "*Dimensionality reduction maps a set of high-dimensional data points down to a low number of dimensions (e.g. 2 or 3 dimensions for visualisation). This low-dimensional representation is an approximation, but should capture as much of the original high-dim structure as possible. In other words, points that are close together in high-dim space should stay close together in low-dim space, and points that are far apart should stay far apart.*\n",
    "\n",
    "*We can then use this low-dimensional approximation as our new set of features for a machine learning model.*\n",
    "\n",
    "3. What's the purpose of clustering?\n",
    "\n",
    "*Given a set of data points, the goal of clustering is to assign groups of points to separate \"clusters\". Similar points should be grouped in the same cluster, and dissimilar points should be in different clusters.*\n",
    "\n",
    "*Clustering gives us insight into the intrinsic structure of the data; we would typically expect points within the same cluster to behave similarly. For example, it is often the case that points within the same cluster map to the same target in regression/classification.*\n",
    "\n",
    "4. What is the difference between a categorical and numerical feature?\n",
    "\n",
    "*A categorical feature takes on one of a number of classes, e.g. a gender feature with values \"male\" or \"female\" or the make of a car.*\n",
    "\n",
    "*A numerical feature is a feature that can be any real number, e.g. height or weight.*\n",
    "\n",
    "5. How does linear regression work?\n",
    "\n",
    "*In linear regression, we assume that the target is a linear function of the features. In other words, the target is a weighted sum of the features (possibly with a constant \"intercept\" added on).*\n",
    "\n",
    "*To make a prediction for a new input, we simply calculate this weighted sum of its features to give us the predicted target.*\n",
    "\n",
    "*Training a linear regression model involves learning the weights for the weighted sum from a training set. The most straightforward way of doing this involves finding the weights that minimise the sum of squared errors over the training set. I could tell you more, but you'd have to pay me.*\n",
    "\n",
    "6. How does the naive Bayes algorithm work?\n",
    "\n",
    "*Naive Bayes is used for classification. It assumes that the feature values are independent given the target class, and this assumption allows us to easily predict the class for a new input using Bayes' theorem.*\n",
    "\n",
    "*Training naive Bayes involves estimating a 1D distribution for each individual feature from the training data (over each separate class). This distribution might be Gaussian for a continuous feature or a multinomial distribution for a categorical feature.*\n",
    "\n",
    "*We can use each learned feature distribution to estimate the probabilities of obtaining a new input's feature values for each class. Because of our independence assumption, we can then apply Bayes' theorem to derive the probability of each class given the new feature values.*\n",
    "\n",
    "7. What's the purpose of splitting a data set into training and test sets?\n",
    "\n",
    "*The machine learning model is trained over the training set; typically this involves trying to minimise some sort of error over the training set.*\n",
    "\n",
    "*To assess the performance of the model, we should compute the error over a completely \"unseen\" test set. This will give us an unbiased estimate of how well the model will generalise to new data.*\n",
    "\n",
    "*Using the training set to compute the error would give an overly optimistic estimate, as the model has already seen all the data in the training set and used it to fit its parameters.*\n",
    "\n",
    "8. What is overfitting? How can you detect when your machine learning algorithm is overfitting?\n",
    "\n",
    "*Overfitting happens when the model fits to the noise in the data instead of learning the underlying function mapping inputs to targets.*\n",
    "\n",
    "*If the error over the test set is much lower than the error over the training set, this indicates that overfitting has occurred.*\n",
    "\n",
    "9. How can overfitting be combatted?\n",
    "\n",
    "*Generally overfitting occurs when the model is too complex relative to the amount of training data we've been given. Some ways to combat it:*\n",
    "\n",
    "*Penalise overly complex models using \"regularisation\". These techniques squash parameters towards zero, reducing model complexity.*\n",
    "\n",
    "*Assess generalisation error over a separate validation set (or using cross-validation) and make sure this is low*\n",
    "\n",
    "*Reduce the number of features used, either by manually preprocessing the data and eliminating irrelevant features or by dimensionality reduction*\n",
    "\n",
    "10. Name two ways of evaluating the performance of a regression algorithm.\n",
    "\n",
    "*Mean-squared error over the test set: just the average of the squared differences between the predicted targets and the actual targets.*\n",
    "\n",
    "*Coefficient of determination $R^2$ over the test set: when the predicted targets are plotted against the actual targets, measures the deviation from the \"identity line\" of perfect prediction.*\n",
    "\n",
    "11. Name two ways of evaluating the performance of a classification algorithm.\n",
    "\n",
    "*Accuracy over the test set: Simplest way of assessing the performance of a classifier. Just the number of correctly classified points.*\n",
    "\n",
    "*Confusion matrix over the test set: Shows the predicted classes vs the actual classes in a matrix. For example, the matrix entry with row \"dog\" and column \"cat\" shows the number of test observations with actual class \"dog\" but predicted class \"cat\".*\n",
    "\n",
    "*For a good model, the diagonal elements of the confusion matrix should be much greater than those off the diagonal.*\n",
    "\n",
    "12. How does k-NN work?\n",
    "\n",
    "*k-nearest neighbours can be used for both classification and regression.*\n",
    "\n",
    "*For a new input, we make a prediction by simply combining the outputs of the k nearest neighbours of the new input.*\n",
    "\n",
    "*In the case of classification, we take the majority vote of the output classes of the k nearest neighbours.*\n",
    "\n",
    "*For regression, we take the average of the output values of the k nearest neighbours.*\n",
    "\n",
    "13. How does a support vector machine work?\n",
    "\n",
    "*In the case of a linear SVM with a binary target (i.e. just 2 target classes), the SVM will attempt to learn a \"hyperplane\" in feature space separating the 2 classes.*\n",
    "\n",
    "*So for a new input, we simply see which side of the hyperplane the input lies on and use this to predict the target class.*\n",
    "\n",
    "*A linear SVM learns the hyperplane that gives rise to the largest separation (the \"margin\") between the two classes. This is called the \"maximum-margin\" classifier.*\n",
    "\n",
    "*Unless the data is perfectly linearly separable, some data will fall into the margin as we won't have perfect separation. So what we do is trade off the size of the margin vs. the number of points that fall into the margin. This trade-off can be specified via an SVM parameter.*\n",
    "\n",
    "14. What's the purpose of a validation set?\n",
    "\n",
    "*A validation set is used to perform model selection, especially in terms of choosing parameters that control model complexity, by assessing the generalisation performance of the algorithm on this validation set with some kind of accuracy metric. For example, we might choose a parameter that controls how much to penalise complex models, i.e. the trade-off between the model bias and its variance.*\n",
    "\n",
    "*Or we might even create multiple different models and choose the one with the best performance over the validation set.*\n",
    "\n",
    "15. How does a decision tree work?\n",
    "\n",
    "16. What is logistic regression?\n",
    "\n",
    "17. What is cross-validation?\n",
    "\n",
    "18. What is underfitting? How can you detect when your machine learning algorithm is underfitting?\n",
    "\n",
    "19. Explain in simple terms how machine learning algorithms trade off bias against variance.\n",
    "\n",
    "20. What is the curse of dimensionality and how would you combat it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "height = (180, 175, 155)\n",
    "weight = (75, 85, 65)\n",
    "gender = (\"male\", \"female\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
