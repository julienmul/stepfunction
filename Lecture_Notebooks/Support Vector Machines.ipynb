{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "In the Naive Bayes notebook, we classified newsgroup posts into 4 separate groups based on the posts' textual content alone.\n",
    "\n",
    "We're going to try classifying the same content again, but this time using a support vector machine (SVM).\n",
    "\n",
    "1. Download the newsgroup posts for 'alt.atheism', 'soc.religion.christian', 'comp.graphics' and 'sci.med' as before. However, this time use `subset='all'` to download *all* the posts instead of getting separate training and test sets. You should also pass `remove=('headers', 'footers', 'quotes')` into `fetch_20newsgroups` make this classification task harder. Put the newsgroup posts into a variable called `twenty_data`.\n",
    "\n",
    "2. Create a term-document matrix using `CountVectorizer()` and store it in new variable `X`.\n",
    "\n",
    "3. Put twenty_data.target into a new variable `y`. Recall that we want to learn the mapping between each document's term counts `X` and the newsgroup category `y`.\n",
    "\n",
    "4. Use sklearn's `train_test_split()` function to split `X` and `y` into separate training and test sets, with 15% of the data in the test set.  Call the training set's inputs `X_train` and outputs `y_train`.\n",
    "\n",
    "5. Use the `LinearSVC` model to train a linear SVM over the training set. For now, use `C=1000` as the only parameter.\n",
    "\n",
    "6. Evaluate the performance of this model using metrics similar to those in the Naive Bayes notebook.\n",
    "\n",
    "6. Apply `train_test_split()` to `X_train` and `y_train` again to produce a training and *validation* set. Put 15% of the data into the validation set. Notice that our new training set is now smaller than before.\n",
    "\n",
    "7. The purpose of the validation set is to determine the best parameters for the SVM. We'll train the SVM over the training set multiple times with different sets of parameters, assessing its performance over the validation set each time. The parameters giving rise to the best performance are the ones we'll choose. \n",
    "\n",
    "8. Write a `for` loop to train the SVM multiple times with the parameter `C` taking values in `[1, 10, 100, 1000]`. Find the value of `C` that gives rise to the highest accuracy over the validation set. (A better way to perform the parameter search is to use a technique called *cross-validation* in conjunction with sklearn's `GridSearchCV()` function, but this simpler approach will do for now.)\n",
    "\n",
    "9. Merge your training and validation sets together to obtain a larger training set again. Train an SVM with the best value of `C` found above and evaluate its performance over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
