{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_data = fetch_20newsgroups(subset='all',\n",
    "                                 categories=categories,\n",
    "                                 shuffle=True,\n",
    "                                 remove=('headers', 'footers', 'quotes'),\n",
    "                                 random_state=0)\n",
    "\n",
    "twenty_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3759\n",
      "First target is alt.atheism\n",
      "First document is \n",
      "\n",
      "\n",
      "But of course YOUR version of YOUR position has been included in the\n",
      "Charley Challenges, so your claim above is a flat-out lie.  Further,\n",
      "only last week you claimed that you \"might not\" answer the Challenges\n",
      "because you were turned off by \"included text\".  So which is it, do\n",
      "you want your context included in my articles or not?  Come to think\n",
      "of it, this contradiction has the makings of a new entry in the next\n",
      "Challenges post.\n",
      "\n",
      "By the way, I've kept every bloody thing that you've written related\n",
      "to this thread, and will be only too pleased to re-post any of it to\n",
      "back my position.  You seem to have forgotten that you leave an\n",
      "electronic paper trail on the net.\n",
      "\n",
      "\n",
      "\n",
      "Now, now, let's not change the subject.  Wouldn't it be best to finish\n",
      "up the thread in question before you begin new ones?\n"
     ]
    }
   ],
   "source": [
    "print(len(twenty_data.target))\n",
    "print(\"First target is\", twenty_data.target_names[twenty_data.target[0]])\n",
    "print(\"First document is\", twenty_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3759, 38181)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Set up count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# First fit, then transform\n",
    "# I.e. first count the number of words in each document,\n",
    "# and then convert each document into a vector of word counts\n",
    "X = count_vectorizer.fit_transform(twenty_data.data)\n",
    "\n",
    "# 'shape' gives us the number of rows and number of columns\n",
    "# of X\n",
    "# In this case, the number of rows is the number of documents\n",
    "# And the number of columns is the number of individual words\n",
    "print(X.shape)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = twenty_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = training set inputs (each input is a term-document matrix)\n",
    "# y_train = training set outputs (each output is a category like 'graphics', 'medicine', 'christianity')\n",
    "# X_test = test set inputs (again, each input is a t-d matrix)\n",
    "#Â y_test = test set outputs (again, a category)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1000, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Say what model I want to use\n",
    "model = LinearSVC(C=1000)\n",
    "\n",
    "# Learn the relationship between the inputs and output\n",
    "# The first parameter represents the inputs/features\n",
    "# The second parameter represents the outputs/targets\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy is 0.737588652482\n"
     ]
    }
   ],
   "source": [
    "# X_test contains the test set inputs\n",
    "# These inputs are unseen by the model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# y_test contains the correct categories\n",
    "# predicted contains our predicted categories\n",
    "# Accuracy = Percentage of correct predictions\n",
    "print(\"Test set accuracy is\", np.mean(predicted == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.68      0.59      0.63       116\n",
      "         comp.graphics       0.84      0.79      0.82       155\n",
      "               sci.med       0.86      0.68      0.76       140\n",
      "soc.religion.christian       0.62      0.85      0.72       153\n",
      "\n",
      "           avg / total       0.76      0.74      0.74       564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,\n",
    "                            predicted,\n",
    "                            target_names=twenty_data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for C = 1 is 0.7729166666666667\n",
      "Test set accuracy for C = 10 is 0.75625\n",
      "Test set accuracy for C = 100 is 0.7645833333333333\n",
      "Test set accuracy for C = 1000 is 0.75\n"
     ]
    }
   ],
   "source": [
    "for C in (1, 10, 100, 1000):\n",
    "    model = LinearSVC(C=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_validation)\n",
    "    print(\"Test set accuracy for C = {0} is {1}\".format(C, np.mean(predicted == y_validation)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
